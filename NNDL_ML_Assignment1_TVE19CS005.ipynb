{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NNDL_ML_Assignment1_TVE19CS006.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##COLLEGE OF ENGINEERING, TRIVANDRUM\n",
        "##DEPARTMENT OF COMPUTER SCIENCE & ENGINEERING\n",
        "##S5 CSE â€“ FIRST ASSIGNMENT, 19th FEBRUARY 2022\n",
        "##CST 395:NEURAL NETWORKS AND DEEP LEARNING\n",
        "Adithya Kurien Peter<br>\n",
        "TVE19CS005<br>\n",
        "S5 CS<br>\n",
        "Access the Github Repo From : [This Github Repo](https://github.com/aish2002/NNDL-Assignment-1-TVE19CS006)\n",
        "\n"
      ],
      "metadata": {
        "id": "XTWIcUi7yhsn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PROBLEM STATEMENT**\n",
        "\n",
        "Design a simple Neural Network on MNIST Handwritten Digit Dataset. You can\n",
        "decide the number of layers and number of neurons in your network. Use cross\n",
        "entropy loss function with adam optimizer for your model. The performance\n",
        "measurement can be done in terms of accuracy. Compare the performances of\n",
        "at least two different models created by you by varying the number of layers\n",
        "and number of neurons in hidden layers. Also write an analysis of your two\n",
        "models in terms of number of parameters and epochs."
      ],
      "metadata": {
        "id": "1zoBrTtE5UiH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import mean\n",
        "from numpy import std\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "6-JWT36-py4B"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqK-WXcGnYfh",
        "outputId": "c1fe83c3-5691-44bb-a35d-d8eb5ddd5f53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "Train: X=(60000, 28, 28), y=(60000,)\n",
            "Test: X=(10000, 28, 28), y=(10000,)\n"
          ]
        }
      ],
      "source": [
        "# load dataset\n",
        "(trainX, trainy), (testX, testy) = mnist.load_data()\n",
        "# summarize loaded dataset\n",
        "print('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\n",
        "print('Test: X=%s, y=%s' % (testX.shape, testy.shape))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "\n",
        "# reshape dataset to have a single channel\n",
        "trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
        "testX = testX.reshape((testX.shape[0], 28, 28, 1))"
      ],
      "metadata": {
        "id": "OWbZWjpJoFDC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# one hot encode target values\n",
        "trainY = to_categorical(trainY)\n",
        "testY = to_categorical(testY)"
      ],
      "metadata": {
        "id": "gCdkhuFNn5-h"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert from integers to floats\n",
        "train_norm = trainX.astype('float32')\n",
        "test_norm = testX.astype('float32')\n",
        "# normalize to range 0-1\n",
        "trainX = train_norm / 255.0\n",
        "testX = test_norm / 255.0"
      ],
      "metadata": {
        "id": "Vrai0sxdoilV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First NN Model with 2 Layers"
      ],
      "metadata": {
        "id": "5EcaKCi_9OdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def define_model_1():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Flatten(input_shape=(28, 28)))\n",
        "\tmodel.add(Dense(300, activation='relu'))\n",
        "\tmodel.add(Dense(10, activation='softmax'))\n",
        "\t# compile model\n",
        "\topt = Adam(learning_rate=0.01)\n",
        "\tmodel.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "_tkx01UbouGr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate a model using k-fold cross-validation\n",
        "def evaluate_model_1():\n",
        "    scores, histories = list(), list()\n",
        "    # define model\n",
        "    model = define_model_1()\n",
        "    print(model.summary())\n",
        "    # fit model\n",
        "    history = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=1)\n",
        "    # evaluate model\n",
        "    _, acc = model.evaluate(testX, testY, verbose=1)\n",
        "    print('> %.3f' % (acc * 100.0))\n",
        "    # stores scores\n",
        "    scores.append(acc)\n",
        "    histories.append(history)\n",
        "    return scores, histories"
      ],
      "metadata": {
        "id": "cxa4ol6AqMW-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores, histories = evaluate_model_1()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0B8Ympxsqz-l",
        "outputId": "9c91675e-70e3-4ae4-ac43-31ae7651c052"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 300)               235500    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                3010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 238,510\n",
            "Trainable params: 238,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2464 - accuracy: 0.9287 - val_loss: 0.1517 - val_accuracy: 0.9569\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1623 - accuracy: 0.9556 - val_loss: 0.1639 - val_accuracy: 0.9593\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1438 - accuracy: 0.9625 - val_loss: 0.1917 - val_accuracy: 0.9609\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1266 - accuracy: 0.9671 - val_loss: 0.2269 - val_accuracy: 0.9529\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1314 - accuracy: 0.9673 - val_loss: 0.1832 - val_accuracy: 0.9646\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1188 - accuracy: 0.9712 - val_loss: 0.1848 - val_accuracy: 0.9608\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1054 - accuracy: 0.9736 - val_loss: 0.2244 - val_accuracy: 0.9568\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1092 - accuracy: 0.9740 - val_loss: 0.2102 - val_accuracy: 0.9617\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0983 - accuracy: 0.9768 - val_loss: 0.2212 - val_accuracy: 0.9652\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0985 - accuracy: 0.9768 - val_loss: 0.2401 - val_accuracy: 0.9652\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.2401 - accuracy: 0.9652\n",
            "> 96.520\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Second NN Model with 4 Layers"
      ],
      "metadata": {
        "id": "YNSLXk-u9tMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def define_model_2():\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=(28, 28)))\n",
        "    model.add(Dense(300, activation='relu'))\n",
        "    model.add(Dense(180, activation='relu'))\n",
        "    model.add(Dense(80, activation='relu'))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    # compile model\n",
        "    opt = Adam(learning_rate=0.01)\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "x6w_XnhNrRzK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate a model using k-fold cross-validation\n",
        "def evaluate_model_2():\n",
        "    scores, histories = list(), list()\n",
        "    # define model\n",
        "    model = define_model_2()\n",
        "    print(model.summary())\n",
        "    # fit model\n",
        "    history = model.fit(trainX, trainY, epochs=10, batch_size=32, validation_data=(testX, testY), verbose=1)\n",
        "    # evaluate model\n",
        "    _, acc = model.evaluate(testX, testY, verbose=1)\n",
        "    print('> %.3f' % (acc * 100.0))\n",
        "    # stores scores\n",
        "    scores.append(acc)\n",
        "    histories.append(history)\n",
        "    return scores, histories"
      ],
      "metadata": {
        "id": "JZ4eFXbOsasR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execute the Second Model Training"
      ],
      "metadata": {
        "id": "aU81LR-E9yJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores, histories = evaluate_model_2()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAWnThTJtuBb",
        "outputId": "f144d936-1089-40ad-f1c0-88a565b43953"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 300)               235500    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 180)               54180     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 80)                14480     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                810       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 304,970\n",
            "Trainable params: 304,970\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 11s 5ms/step - loss: 0.3116 - accuracy: 0.9157 - val_loss: 0.2153 - val_accuracy: 0.9433\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2023 - accuracy: 0.9492 - val_loss: 0.2368 - val_accuracy: 0.9419\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1733 - accuracy: 0.9574 - val_loss: 0.1564 - val_accuracy: 0.9608\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1571 - accuracy: 0.9617 - val_loss: 0.1736 - val_accuracy: 0.9610\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1602 - accuracy: 0.9621 - val_loss: 0.2125 - val_accuracy: 0.9591\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1395 - accuracy: 0.9663 - val_loss: 0.1902 - val_accuracy: 0.9649\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1508 - accuracy: 0.9663 - val_loss: 0.2610 - val_accuracy: 0.9509\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1260 - accuracy: 0.9716 - val_loss: 0.1338 - val_accuracy: 0.9686\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1162 - accuracy: 0.9732 - val_loss: 0.1982 - val_accuracy: 0.9609\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1256 - accuracy: 0.9727 - val_loss: 0.1576 - val_accuracy: 0.9673\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1576 - accuracy: 0.9673\n",
            "> 96.730\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis Report"
      ],
      "metadata": {
        "id": "rV1cpaA-6egR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2 Deep Learning Models using Neural Network architecture on the MNIST dataset were developed. First one has 2 NN layers and the second model uses 4 NN layers both with softmax layer activation at the top and relu activation function on other layers. <br> <br>\n",
        "\n",
        "For the first model,\n",
        "\n",
        "Number of Layers = 4\n",
        "\n",
        "Number of Trainable Parameters : 206,710\n",
        "\n",
        "Validation Accuracy = 96.52% \n",
        "\n",
        "Validation Loss = 0.2401 <br> <br>\n",
        "\n",
        "\n",
        "For the second model, \n",
        "\n",
        "Number of Layers = 4\n",
        "\n",
        "Validation Accuracy = 96.73% \n",
        "\n",
        "Validation Loss of = 0.1576\n",
        "\n",
        "Number of Trainable Parameters :252,428\n",
        "\n",
        "Clearly Second Model with better validation accuracy is having better performance.\n",
        "<br><br>\n",
        "\n",
        "**Submitted by,**\n",
        "\n",
        "**Adithya Kurien Peter**\n",
        "\n",
        "**S5 CSE**\n",
        "\n",
        "**TVE19CS005**\n"
      ],
      "metadata": {
        "id": "_NI1U9nq6hK_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gw03szZbFW-5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}